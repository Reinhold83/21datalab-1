import numpyfrom system import __functioncontrolfolderimport modelhelper as mhfrom timeseries import TimeSeriesthresholdScorer= {    "name":"thresholdScorer",    "type":"function",    "functionPointer":"threshold.threshold_scorer",   #filename.functionname    "autoReload":True,                                 #set this to true to reload the module on each execution    "children":[        {"name":"input","type":"referencer"},                  # the output column        {"name":"output","type":"referencer"},        {"name":"streaming","type":"const","value":False},    #if set to true, we only update the values in the output which are not finite        {"name":"annotations","type":"referencer"},             #the user annotations        __functioncontrolfolder    ]}thresholdScorer2= {    "name":"thresholdScorer2",    "type":"function",    "functionPointer":"threshold.threshold_scorer_2",           #filename.functionname    "autoReload":True,                                          #set this to true to reload the module on each execution    "children":[        {"name":"input","type":"referencer"},                   # the inputs, must be columns of one table        {"name":"output","type":"folder"},                      # the output columns, these are generated by the scorer and placed here, and also "connected" to the table                                                                # the outputs are named as the inputs, but with _score ending, plus we have the columns _total_score, and _differential        {"name":"annotations","type":"referencer"},             # the user annotations        {"name":"annotationsFilter","type":"const","value":[]}, # a list of strings to filter tags, if an annotation holds one of the filter tags, then we take it in        {"name":"annotations2", "type": "referencer"},         # the additional user annotations, if given, these must OVERLAP with the annotations, it is another filter in the time        {"name":"annotationsFilter2", "type": "const", "value": []}, # a list of strings to filter tags, if an annotation holds one of the filter tags, then we take it in        {"name":"thresholds","type":"referencer"},              # pointing to the thresholds        {"name":"incremental","type":"const","value":False},    # if incremental is set, then we only score areas that we haven't scored yet        __functioncontrolfolder                                 # signal "reset" is used to initialize the function, create and hook the outputs, reset all values    ]}# how to model:# widget.scoreVariables  -> scorer.output.scores# widget.observerVariables.targets -> widget.scoreVariables# widget.observerVariables.properties: forwardrefs and children# scorer.input -> table.variables# scorer.thresholds -> to where the thresholds are# scorer annotations, annotationsFilter needs at least one area to work on: create a region covering all times,set the end into the far future and you are save!#thresholdScorer3= {    "name":"thresholdScorer3",    "type":"function",    "functionPointer":"threshold.threshold_scorer_3",           #filename.functionname    "autoReload":True,                                          #set this to true to reload the module on each execution    "children":[        {"name":"input","type":"referencer"},                   # the inputs, must be columns of one table        {"name":"output","type":"folder","children":[           # here only the total and diff scores enc            {"name":"scores","type":"folder"}                   # the output columns, these are generated by the scorer and placed here, and also "connected" to the table, widget.scoreVariables must point to here        ]},                                                                # the outputs are named as the inputs, but with _score ending, plus we have the columns _total_score, and _differential        {"name":"annotations","type":"referencer"},             # the user annotations        {"name":"annotationsFilter","type":"const","value":[]}, # a list of strings to filter tags, if an annotation holds one of the filter tags, then we take it in        {"name":"annotations2", "type": "referencer"},         # the additional user annotations, if given, these must OVERLAP with the annotations, it is another filter in the time        {"name":"annotationsFilter2", "type": "const", "value": []}, # a list of strings to filter tags, if an annotation holds one of the filter tags, then we take it in        {"name":"thresholds","type":"referencer"},              # pointing to the thresholds        {"name":"incremental","type":"const","value":False},    # if incremental is set, then we only score areas that we haven't scored yet        __functioncontrolfolder                                 # signal "reset" is used to initialize the function, create and hook the outputs, reset all values    ]}# how to model:# widget.scoreVariables  -> scorer.output.scores# widget.observerVariables.targets -> widget.scoreVariables# widget.observerVariables.properties: forwardrefs and children# scorer.input -> table.variables# scorer.thresholds -> to where the thresholds are# scorer annotations, annotationsFilter needs at least one area to work on: create a region covering all times,set the end into the far future and you are save!#thresholdScorer4={    "name":"thresholdScorer3",    "type":"function",    "functionPointer":"threshold.threshold_scorer_3",           #filename.functionname    "autoReload":True,                                          #set this to true to reload the module on each execution    "children":[        {"name":"input","type":"referencer"},                   # the inputs, must be columns of one table        {"name":"output","type":"folder","children":[           # here only the total and diff scores enc            {"name":"scores","type":"folder"}                   # the output columns, these are generated by the scorer and placed here, and also "connected" to the table, widget.scoreVariables must point to here        ]},                                                                # the outputs are named as the inputs, but with _score ending, plus we have the columns _total_score, and _differential        {"name":"annotations","type":"referencer"},             # the user annotations        {"name":"annotationsFilter","type":"const","value":[]}, # a list of strings to filter tags, if an annotation holds one of the filter tags, then we take it in        {"name":"thresholds","type":"referencer"},              # pointing to the thresholds        __functioncontrolfolder                                 # signal "reset" is used to initialize the function, create and hook the outputs, reset all values    ]}thresholdDrillDown= {    "name":"thresholdDrillDown",    "type":"function",    "functionPointer":"threshold.threshold_drill_down",           #filename.functionname    "autoReload":True,                                          #set this to true to reload the module on each execution    "children":[        {"name":"widget","type":"referencer"},                  # the widget on which to work        {"name":"drillVariables","type":"referencer"},          # the variables which have an error in the selected time        __functioncontrolfolder                                 # all values    ]}"""    # for initialization: hook the drilldown.widget to the widget (to find variables etc),    # enable the two observers"""thresholdDrillDownPipeLine = {    "name": "thresholdDrillDownPipeLine",    "type": "folder",    "children":[        {   "name":"drilldown",            "type": "function",            "functionPointer": "threshold.threshold_drill_down",  # filename.functionname            "autoReload": True,  # set this to true to reload the module on each execution            "children": [                {"name": "widget", "type": "referencer"},  # the widget on which to work                {"name": "drillVariables", "type": "referencer"},  # the variables which have an error in the selected time                __functioncontrolfolder            ]        },        {"name":"cockpit","type":"const","value":"customui/cockpitdrilldown.htm"},        { "name":"selectionObserver","type":"observer",  "children":[            {"name": "enabled", "type": "const", "value": False},           # turn on/off the observer            {"name": "triggerCounter","type":"variable","value":0},         #  increased on each trigger            {"name": "lastTriggerTime","type":"variable","value":""},       #  last datetime when it was triggered            {"name": "targets","type":"referencer"},                        #  pointing to the nodes observed            {"name": "properties","type":"const","value":["value"]},        #  properties to observe [“children”,“value”, “forwardRefs”]            {"name": "onTriggerFunction","type":"referencer","references":["thresholdDrillDownPipeLine.drilldown"]},              #  the function(s) to be called when triggering            {"name": "triggerSourceId","type":"variable"},                  #  the sourceId of the node which caused the observer to trigger            {"name": "hasEvent","type":"const","value":False},              # set to event string iftrue if we want an event as well            {"name": "eventString","type":"const","value":"observerdefaultevent"},              # the string of the event            {"name": "eventData","type":"const","value":{"text":"observer status update"}}# the value-dict will be part of the SSE event["data"] , the key "text": , this will appear on the page,            ]        },        {"name": "resultObserver", "type": "observer", "children": [            {"name": "enabled", "type": "const", "value": False},  # turn on/off the observer            {"name": "triggerCounter", "type": "variable", "value": 0},  # increased on each trigger            {"name": "lastTriggerTime", "type": "variable", "value": ""},  # last datetime when it was triggered            {"name": "targets", "type": "referencer","references": ["thresholdDrillDownPipeLine.drilldown.drillVariables"]},  # pointing to the nodes observed            {"name": "properties", "type": "const", "value": ["forwardRefs"]}, # properties to observe [“children”,“value”, “forwardRefs”]            {"name": "onTriggerFunction", "type": "referencer"}, # the function(s) to be called when triggering            {"name": "triggerSourceId", "type": "variable"}, # the sourceId of the node which caused the observer to trigger            {"name": "hasEvent", "type": "const", "value": True}, # set to event string iftrue if we want an event as well            {"name": "eventString", "type": "const", "value": "drilldown.result"},  # the string of the event            {"name": "eventData", "type": "const", "value": {"text": "observer status update"}} # the value-dict will be part of the SSE event["data"] , the key "text": , this will appear on the page,            ]        },    ]}def threshold_scorer_2_init(functionNode):    """        initialization:        create all outputs, hook them    """    logger = functionNode.get_logger()    logger.debug("threshold_scorer_2_init()")    #get some helper nodes for later:    inputNodes = functionNode.get_child("input").get_leaves()    if not inputNodes:        logger.error("no input nodes, exit")        return    tableNode = inputNodes[0].get_table_node()    if not tableNode:        logger.error("table not found, exit")        return    tableLen = len(inputNodes[0].get_value())    timeNode = tableNode.get_table_time_node()    if not timeNode:        logger.error("time node not found")        return    #delete all outputs if there are any    #outputNodes = functionNode.get_child("output").get_children()    #for node in outputNodes:    #    logger.info(f"deleting node {node.get_browse_path()}")    #    node.delete()    #now create all output nodes fresh    outputNode = functionNode.get_child("output")    for inputNode in inputNodes:        if inputNode.get_id() == timeNode.get_id():            continue # skip the time node        newName = inputNode.get_name()+"_score"        logger.info(f"create node {newName}")        newNode = outputNode.create_child(newName,type="column")        newNode.connect_to_table(tableNode) #this will reset the values and hook it to the table    #also add two more:    outputNode.create_child("_total_score",type="column").connect_to_table(tableNode)    outputNode.create_child("_differential", type="column").connect_to_table(tableNode)    outputNode.get_child("_differential").set_value(numpy.full(tableLen,False,dtype=numpy.float64))def get_time_indices_of_annotation_tag(annotations,timeNode,filterTags):    """        this functions returns a vector of true/false, it is true if we have an annotations of the given tags on that time        Args:            annotations: list of annotations nodes            timeNode: the time node of the table            tags : a list of tags to look for        Return:            vector to mask the time areas    """    tableLen = len(timeNode.get_value())    timeIndices = numpy.full(tableLen, False,dtype=numpy.bool)  # True on the time points we want to score, , false for not score here    if "threshold" in filterTags:        filterTags.remove("threshold")    if filterTags !=[]:        for anno in annotations:            if anno.get_child("type").get_value() != "time":                continue # only time annotations            tags = anno.get_child("tags").get_value()            if not any([tag in filterTags for tag in tags]):                continue            #take the indices            indices = list(timeNode.get_time_indices(anno.get_child("startTime").get_value(),anno.get_child("endTime").get_value()))            timeIndices[indices]=True #fancy indexing    return timeIndicesdef threshold_scorer_2(functionNode):    """        the threshold-scorer:        it goes through the annotations and picks the time areas where the tag of the annotation match the filter        it then goes through the annnotations2 and pick the time ares where the tag matches filter2        those two time areas are "AND" merged: it is useful to define additional "regions"        then we iterate over the thresholds and look for annotations of type "threshold"        for each variable only one threshold (the last in the list) will be evaluated        the variables to score on are the variables in the inputs which also have a threshold tag given        the time areas to score on is either the full range (differential = false)        or just the missing areas (differential = True)        modelling:        - put the scorer where you like        - connect annotations and inputs        - execute it once with signal "reset"        - connect the widgets.scoreVariables to the output folder (to make them scores)        - install an observer (event:timeSeriesWidget.variables) in the widget to watch the selectedVariables and scoreVariables value change        Args: the functionNode    """    logger = functionNode.get_logger()    logger.debug(f'threshold_scorer_2() {functionNode.get_child("control").get_child("signal").get_value()}')    #check for initialization    if functionNode.get_child("control").get_child("signal").get_value() == "reset":        #this is the first call, we just initialize        threshold_scorer_2_init(functionNode)        functionNode.get_child("control").get_child("signal").set_value("")        return    inputNodes = functionNode.get_child("input").get_leaves()    tableNode = inputNodes[0].get_table_node()    timeNode = tableNode.get_table_time_node()    tableLen = len(timeNode.get_value())    totalOutputNode = functionNode.get_child("output").get_child("_total_score")    progressNode = functionNode.get_child("control").get_child("progress")    #first find the time areas to work on for the scorer, this is the overlap area of annotations and annotations2    timeIndices = numpy.full(tableLen,False,dtype=numpy.bool) # True on the time points we want to score, , false for not score here    annos1 = functionNode.get_child("annotations").get_leaves()    annos1Filter = functionNode.get_child("annotationsFilter").get_value()    for anno in annos1:        logger.debug(f"processing anno {anno.get_name()}")        if anno.get_child("type").get_value() != "time":            continue # only time annotations        if annos1Filter:            #we must filter            tags = anno.get_child("tags").get_value()            if not any([tag in annos1Filter for tag in tags]):                continue        #take the indices        indices = list(timeNode.get_time_indices(anno.get_child("startTime").get_value(),anno.get_child("endTime").get_value()))        timeIndices[indices]=True #fancy indexing    #now merge with the seconds selection    annos2 = functionNode.get_child("annotations2").get_leaves()    annos2Filter = functionNode.get_child("annotationsFilter2").get_value()    for anno in annos2:        if anno.get_child("type").get_value() != "time":            continue # only time annotations        if annos2Filter:            #we must filter            tags = anno.get_child("tags").get_value()            if not any([tag in annos2Filter for tag in tags]):                continue        #take the indices        indices = list(timeNode.get_time_indices(anno.get_child("startTime").get_value(),anno.get_child("endTime").get_value()))        mask = numpy.full(tableLen,False,dtype=numpy.bool)        mask[indices] = True        timeIndices = numpy.logical_and(timeIndices,mask)    #finally merge with the "differential" variable if required    if functionNode.get_child("incremental").get_value():        #we must work incremental, so we merge the data once more with the mask of the differential        oldMask = functionNode.get_child("output").get_child("_differential").get_value() # the mask is true where a scoring has been done in the last round already        mask = oldMask != True # we get an array of [true, false,....] for the elementwise expression != True        timeIndices = numpy.logical_and(timeIndices,mask) # apply it on the mask        newMask = oldMask or mask # unify merge the old and new mask        functionNode.get_child("output").get_child("_differential").set_value(newMask) # set all true    else:        functionNode.get_child("output").get_child("_differential").set_value(timeIndices) # write out this area to eval    # now we have in timeIndices the time indices to work on as a true/false mask    # now find the variables and according thresholds    thresholds ={} # a dict holding the nodeid and the threshold thereof (min and max)    for anno in functionNode.get_child("thresholds").get_leaves():        if anno.get_child("type").get_value() != "threshold":            continue # only thresholds        id = anno.get_child("variable").get_leaves()[0].get_id() # the first id of the targets of the annotation target pointer, this is the node that the threshold is referencing to        thisMin  = anno.get_child("min").get_value()        if type(thisMin) is type(None):            thisMin = -numpy.inf        thisMax = anno.get_child("max").get_value()        if type(thisMax) is type(None):            thisMax = numpy.inf        tags = anno.get_child("tags").get_value()        if "threshold" in tags:            tags.remove("threshold")        entry = {"min": thisMin, "max": thisMax,"tags":tags}        if id not in thresholds:            thresholds[id] = [entry]        else:            thresholds[id].append(entry)    total_score = numpy.full(tableLen,numpy.inf,dtype=numpy.float64) # reset all    for counter,node in enumerate(inputNodes):        progressNode.set_value(counter/len(inputNodes))        id = node.get_id()        if id in thresholds:            #must score            logger.debug(f"must score {node.get_browse_path()} ")#with {thresholds[id]['min']}, {thresholds[id]['max']}")            values = node.get_value()            #now find where the limits are over/under            variableTotal = numpy.full(len(values), True,dtype=numpy.bool)            haveAnyGlobal = False            #we start with the global valid thresholds            for entry in thresholds[id]:                if entry["tags"] != []:                    continue # we don't handle thresholds now with are linked to certain annotations                haveAnyGlobal = True                outOfLimit = numpy.logical_or( values < entry['min'], values > entry['max'] )                outOfLimit = numpy.logical_and(outOfLimit,timeIndices) #this is the global time filter (regions etc)                variableTotal = numpy.logical_and(outOfLimit,variableTotal)            if not haveAnyGlobal:                variableTotal = numpy.full(len(values), False, dtype=numpy.bool)            globalOutOfLimit = variableTotal #holds true for outlier and false for ok for the global valid thresholds            #now the ones bound to a annotation tag            variableTotal =  numpy.full(len(values), False,dtype=numpy.bool)            specificResults = numpy.full(len(values), False,dtype=numpy.bool) # holds the areas where the results must be replaced            haveAnyLocal = False            for entry in thresholds[id]:                if entry["tags"] == []:                    continue # those have been handled above                haveAnyLocal = True                outOfLimit = numpy.logical_or( values < entry['min'], values > entry['max'] )                outOfLimit = numpy.logical_and(outOfLimit,timeIndices) #this is the global time filter (regions etc)                #additionally the specific filters:                localFilter = get_time_indices_of_annotation_tag(annos1,timeNode,entry['tags'])                outOfLimit = numpy.logical_and(outOfLimit, localFilter)                #now we have results in outOfLimit which are valid during localFilter                # if we have already results during local Filter then this is another thresholds of the same tags                # we had already earlier, so we will "and" the outoflimit to the total, otherwise "or" it                additionalLocalResultFilter = localFilter & specificResults # true where we have results that must be "and"ed                if (numpy.any(additionalLocalResultFilter)):                    #we have results in an area that has been scored before                    newScore = variableTotal & additionalLocalResultFilter & outOfLimit                    variableTotal[additionalLocalResultFilter]=False                    variableTotal = variableTotal | newScore                else:                    #just invalidade                    variableTotal = numpy.logical_or(outOfLimit, variableTotal)  #                specificResults = numpy.logical_or(specificResults,localFilter) # remember known areas                #variableTotal = numpy.logical_and(outOfLimit,variableTotal) #            if not haveAnyLocal:                variableTotal = numpy.full(len(values), False, dtype=numpy.bool)            #now merge both            globalOutOfLimit[specificResults]=False # invalidate global results where we have specific results            variableTotal = numpy.logical_or(variableTotal,globalOutOfLimit)            outOfLimitIndices = numpy.where(variableTotal==True)            outPutNode = functionNode.get_child("output").get_child( node.get_name()+"_score")            if functionNode.get_child("incremental").get_value():                score = outPutNode.get_value() # take the old and merge            else:                score = numpy.full(tableLen,numpy.inf,dtype=numpy.float64) # rest all            score[timeIndices]=numpy.inf            score[outOfLimitIndices] = values[outOfLimitIndices]            total_score[numpy.isfinite(score)] = -1 #set one where the score is finite, there we have an anomaly            outPutNode.set_value(score)        else:            #this variable is not to be scored but we should delete the old score            outputNode = functionNode.get_child("output").get_child( node.get_name()+"_score")            if outputNode:                if numpy.any(numpy.isfinite(outputNode.get_value())):                    outputNode.set_value(numpy.inf)                    logger.debug(f"reset {outputNode.get_name()}")                else:                    logger.debug(f"skip {outputNode.get_name()}")    totalOutputNode.set_value(total_score)    return Truedef threshold_scorer_3(functionNode):    """        the threshold-scorer:        it goes through the annotations and picks the time areas where the tag of the annotation match the filter        it then goes through the annnotations2 and pick the time ares where the tag matches filter2        those two time areas are "AND" merged: it is useful to define additional "regions"        then we iterate over the thresholds and look for annotations of type "threshold"        for each variable only one threshold (the last in the list) will be evaluated        the variables to score on are the variables in the inputs which also have a threshold tag given        the time areas to score on is either the full range (differential = false)        or just the missing areas (differential = True)        modelling:        - put the scorer where you like        - connect annotations and inputs        - execute it once with signal "reset"        - connect the widgets.scoreVariables to the output folder (to make them scores)        - install an observer (event:timeSeriesWidget.variables) in the widget to watch the selectedVariables and scoreVariables value change        Args: the functionNode    """    logger = functionNode.get_logger()    logger.debug(f'threshold_scorer_2() {functionNode.get_child("control").get_child("signal").get_value()}')    #check for initialization    if functionNode.get_child("control").get_child("signal").get_value() == "reset":        #this is the first call, we just initialize        threshold_scorer_2_init(functionNode)        functionNode.get_child("control").get_child("signal").set_value("")        return    inputNodes = functionNode.get_child("input").get_leaves()    tableNode = inputNodes[0].get_table_node()    timeNode = tableNode.get_table_time_node()    tableLen = len(timeNode.get_value())    outputNodes = functionNode.get_child("output").get_child("scores").get_leaves()    model = functionNode.get_model()    mustTriggerObserver = False    #create and connect the two main outputs    totalOutputNode = functionNode.get_child("output").get_child("_total_score")    if not totalOutputNode:        totalOutputNode=functionNode.get_child("output").create_child("_total_score",properties={"type":"column","creator":functionNode.get_id(),"subType":"score"})        totalOutputNode.connect_to_table(tableNode)    if not functionNode.get_child("output").get_child("_differential"):        diffNode = functionNode.get_child("output").create_child("_differential",properties={"type":"column","creator":functionNode.get_id()})        diffNode.connect_to_table(tableNode)    progressNode = functionNode.get_child("control").get_child("progress")    #first find the time areas to work on for the scorer, this is the overlap area of annotations and annotations2    timeIndices = numpy.full(tableLen,False,dtype=numpy.bool) # True on the time points we want to score, , false for not score here    annos1 = functionNode.get_child("annotations").get_leaves()    annos1Filter = functionNode.get_child("annotationsFilter").get_value()    for anno in annos1:        logger.debug(f"processing anno {anno.get_name()}")        if anno.get_child("type").get_value() != "time":            continue # only time annotations        if annos1Filter:            #we must filter            tags = anno.get_child("tags").get_value()            if not any([tag in annos1Filter for tag in tags]):                continue        #take the indices        indices = list(timeNode.get_time_indices(anno.get_child("startTime").get_value(),anno.get_child("endTime").get_value()))        timeIndices[indices]=True #fancy indexing    #now merge with the seconds selection    annos2 = functionNode.get_child("annotations2").get_leaves()    annos2Filter = functionNode.get_child("annotationsFilter2").get_value()    for anno in annos2:        if anno.get_child("type").get_value() != "time":            continue # only time annotations        if annos2Filter:            #we must filter            tags = anno.get_child("tags").get_value()            if not any([tag in annos2Filter for tag in tags]):                continue        #take the indices        indices = list(timeNode.get_time_indices(anno.get_child("startTime").get_value(),anno.get_child("endTime").get_value()))        mask = numpy.full(tableLen,False,dtype=numpy.bool)        mask[indices] = True        timeIndices = numpy.logical_and(timeIndices,mask)    #finally merge with the "differential" variable if required    if functionNode.get_child("incremental").get_value():        #we must work incremental, so we merge the data once more with the mask of the differential        oldMask = functionNode.get_child("output").get_child("_differential").get_value() # the mask is true where a scoring has been done in the last round already        mask = oldMask != True # we get an array of [true, false,....] for the elementwise expression != True        timeIndices = numpy.logical_and(timeIndices,mask) # apply it on the mask        newMask = oldMask or mask # unify merge the old and new mask        functionNode.get_child("output").get_child("_differential").set_value(newMask) # set all true    else:        functionNode.get_child("output").get_child("_differential").set_value(timeIndices) # write out this area to eval    # now we have in timeIndices the time indices to work on as a true/false mask    # now find the variables and according thresholds    thresholds ={} # a dict holding the nodeid and the threshold thereof (min and max)    for anno in functionNode.get_child("thresholds").get_leaves():        if anno.get_child("type").get_value() != "threshold":            continue # only thresholds        id = anno.get_child("variable").get_leaves()[0].get_id() # the first id of the targets of the annotation target pointer, this is the node that the threshold is referencing to        thisMin  = anno.get_child("min").get_value()        if type(thisMin) is type(None):            thisMin = -numpy.inf        thisMax = anno.get_child("max").get_value()        if type(thisMax) is type(None):            thisMax = numpy.inf        tags = anno.get_child("tags").get_value()        if "threshold" in tags:            tags.remove("threshold")        entry = {"min": thisMin, "max": thisMax,"tags":tags}        if id not in thresholds:            thresholds[id] = [entry]        else:            thresholds[id].append(entry)    total_score = numpy.full(tableLen,numpy.inf,dtype=numpy.float64) # reset all    #the existing outputNodes with no current threshold will be deleted    thresholdVarNames = [functionNode.get_node(id).get_name()+"_score" for id in thresholds]    deleteOld = []    model.disable_observers()# we do not trigger the change of nodes, as this is done later with the values anyways    try:        for node in outputNodes:            if node.get_name() not in thresholdVarNames:                logger.info(f"delete old score {node.get_browse_path()}")                deleteOld.append(node)        for node in deleteOld:            node.delete()            mustTriggerObserver = True        #create needed new ones        outputNodes = functionNode.get_child("output").get_child("scores").get_leaves() # get the remaining fresh        outputNodeNames =[node.get_name() for node in outputNodes]        for  name in thresholdVarNames:            if name not in outputNodeNames:                logger.info(f"create new threshold score {name}")                newScore = functionNode.get_child("output").get_child("scores").create_child(name,properties={"type":"column","subType":"score","creator":functionNode.get_id()})                newScore.connect_to_table(tableNode)                mustTriggerObserver = True    finally:        model.enable_observers()    #now remove the inputNodes from the list which have no threshold to score on    inputNodes=[node for node in inputNodes if node.get_id() in thresholds]    m = functionNode.get_model()    for counter,node in enumerate(inputNodes):        progressNode.set_value(counter/len(inputNodes))        m.disable_observers()        try:            id = node.get_id()            if id in thresholds:                #must score                logger.debug(f"must score {node.get_browse_path()} ")#with {thresholds[id]['min']}, {thresholds[id]['max']}")                values = node.get_value()                #now find where the limits are over/under                variableTotal = numpy.full(len(values), True,dtype=numpy.bool)                haveAnyGlobal = False                #we start with the global valid thresholds                for entry in thresholds[id]:                    if entry["tags"] != []:                        continue # we don't handle thresholds now with are linked to certain annotations                    haveAnyGlobal = True                    outOfLimit = numpy.logical_or( values < entry['min'], values > entry['max'] )                    outOfLimit = numpy.logical_and(outOfLimit,timeIndices) #this is the global time filter (regions etc)                    variableTotal = numpy.logical_and(outOfLimit,variableTotal)                if not haveAnyGlobal:                    variableTotal = numpy.full(len(values), False, dtype=numpy.bool)                globalOutOfLimit = variableTotal #holds true for outlier and false for ok for the global valid thresholds                #now the ones bound to a annotation tag                variableTotal =  numpy.full(len(values), False,dtype=numpy.bool)                specificResults = numpy.full(len(values), False,dtype=numpy.bool) # holds the areas where the results must be replaced                haveAnyLocal = False                for entry in thresholds[id]:                    if entry["tags"] == []:                        continue # those have been handled above                    haveAnyLocal = True                    outOfLimit = numpy.logical_or( values < entry['min'], values > entry['max'] )                    outOfLimit = numpy.logical_and(outOfLimit,timeIndices) #this is the global time filter (regions etc)                    #additionally the specific filters:                    localFilter = get_time_indices_of_annotation_tag(annos1,timeNode,entry['tags'])                    outOfLimit = numpy.logical_and(outOfLimit, localFilter)                    #now we have results in outOfLimit which are valid during localFilter                    # if we have already results during local Filter then this is another thresholds of the same tags                    # we had already earlier, so we will "and" the outoflimit to the total, otherwise "or" it                    additionalLocalResultFilter = localFilter & specificResults # true where we have results that must be "and"ed                    if (numpy.any(additionalLocalResultFilter)):                        #we have results in an area that has been scored before                        newScore = variableTotal & additionalLocalResultFilter & outOfLimit                        variableTotal[additionalLocalResultFilter]=False                        variableTotal = variableTotal | newScore                    else:                        #just invalidade                        variableTotal = numpy.logical_or(outOfLimit, variableTotal)  #                    specificResults = numpy.logical_or(specificResults,localFilter) # remember known areas                    #variableTotal = numpy.logical_and(outOfLimit,variableTotal) #                if not haveAnyLocal:                    variableTotal = numpy.full(len(values), False, dtype=numpy.bool)                #now merge both                globalOutOfLimit[specificResults]=False # invalidate global results where we have specific results                variableTotal = numpy.logical_or(variableTotal,globalOutOfLimit)                outOfLimitIndices = numpy.where(variableTotal==True)                outPutNode = functionNode.get_child("output").get_child("scores").get_child(node.get_name()+"_score")                if functionNode.get_child("incremental").get_value():                    score = outPutNode.get_value() # take the old and merge                else:                    score = numpy.full(tableLen,numpy.inf,dtype=numpy.float64) # rest all                score[timeIndices]=numpy.inf                score[outOfLimitIndices] = values[outOfLimitIndices]                total_score[numpy.isfinite(score)] = -1 #set one where the score is finite, there we have an anomaly                outPutNode.set_value(score)                mustTriggerObserver = True            else:                #this variable is not to be scored but we should delete the old score                outputNode = functionNode.get_child("output").get_child("scores").get_child(node.get_name()+"_score")                if outputNode:                    if numpy.any(numpy.isfinite(outputNode.get_value())):                        outputNode.set_value(numpy.inf)                        mustTriggerObserver = True                        logger.debug(f"reset {outputNode.get_name()}")                    else:                        logger.debug(f"skip {outputNode.get_name()}")        finally:            m.enable_observers()    totalOutputNode.set_value(total_score)    progressNode.set_value(1)    if mustTriggerObserver:        m.notify_observers(functionNode.get_child("output").get_child("scores").get_id(),"children")    return Truedef mask_from_regions(regions, times):    if regions:        result = numpy.full(len(times),False)        for region in regions:            result = result | mh.get_mask_from_interval(times,region["start"],region["end"])    else:        result = numpy.full(len(times),True)    return resultdef out_of_limits(values,mini,maxi):    """    returns a true/fals for out of limits, able to handle nans    """    print("out_of_limits")    work = numpy.copy(values)    workNan = ~numpy.isfinite(work)    work[workNan] = -numpy.inf  # so we don't get a toosmall at nans    tooSmall = work < mini    work[workNan] = +numpy.inf    tooBig = work > maxi    return  tooSmall | tooBig  # numpy.logical_or( values < entry['min'], values > entry['max'] )def threshold_scorer_4(functionNode):    """        the threshold-scorer 4:        - the _total_output and __differential nodes are created if they don't exist        modelling:        - put the scorer where you like        - connect annotations and inputs        - execute it once with signal "reset"        - connect the widgets.scoreVariables to the output folder (to make them scores)        - install an observer (event:timeSeriesWidget.variables) in the widget to watch the selectedVariables and scoreVariables value change        Args: the functionNode    """    logger = functionNode.get_logger()    logger.debug(f'threshold_scorer_4() {functionNode.get_child("control").get_child("signal").get_value()}')    inputNodes = functionNode.get_child("input").get_leaves()    tableNode = inputNodes[0].get_table_node()    columnsNode = tableNode.get_child("columns")    progressNode = functionNode.get_child("control").get_child("progress")    #timeNode = tableNode.get_table_time_node()    #tableLen = len(timeNode.get_value())    outputNodes = functionNode.get_child("output").get_child("scores").get_leaves()    model = functionNode.get_model()    m = functionNode.get_model()    mustTriggerObserver = False    #create and connect the two main outputs    totalOutputNode = functionNode.get_child("output").get_child("_total_score")    if not totalOutputNode:        totalOutputNode=functionNode.get_child("output").create_child("_total_score",properties={"type":"timeseries","creator":functionNode.get_id(),"subType":"score"})        columnsNode.add_references(totalOutputNode) #connect to table    # first find the time areas to work on for all sensors, this is a global filter for all activities    # we store it as a list of start and end time to evaluate for each sensor separately    regionFilter = []    annos1 = functionNode.get_child("annotations").get_leaves()    annos1Filter = functionNode.get_child("annotationsFilter").get_value()    if annos1Filter:        for anno in annos1:            logger.debug(f"processing anno {anno.get_name()}")            if anno.get_child("type").get_value() != "time":                continue # only time annotations                tags = anno.get_child("tags").get_value()                if  any([tag in annos1Filter for tag in tags]):                    regionFilter.append({"start": anno.get_child("startTime").get_value(), "end": anno.get_child("endTime").get_value()})    # we convert all thresholds into a list of dicts for faster access    thresholds ={} # a dict holding the nodeid and the threshold thereof (min and max)    for anno in functionNode.get_child("thresholds").get_leaves():        if anno.get_child("type").get_value() != "threshold":            continue # only thresholds        id = anno.get_child("variable").get_leaves()[0].get_id() # the first id of the targets of the annotation target pointer, this is the node that the threshold is referencing to        thisMin  = anno.get_child("min").get_value()        if type(thisMin) is type(None):            thisMin = -numpy.inf        thisMax = anno.get_child("max").get_value()        if type(thisMax) is type(None):            thisMax = numpy.inf        tags = anno.get_child("tags").get_value()        if "threshold" in tags:            tags.remove("threshold")        entry = {"min": thisMin, "max": thisMax,"tags":tags}        if id not in thresholds:            thresholds[id] = [entry]        else:            thresholds[id].append(entry)    # now create dynamically the needed score variables,    # the existing outputNodes with no current threshold definiton will also be deleted    thresholdVarNames = [functionNode.get_node(id).get_name()+"_score" for id in thresholds]    deleteOld = []    model.disable_observers()# we do not trigger the change of nodes, as this is done later with the values anyways    try:        for node in outputNodes:            if node.get_name() not in thresholdVarNames:                logger.info(f"delete old score {node.get_browse_path()}")                deleteOld.append(node)        for node in deleteOld:            node.delete()            mustTriggerObserver = True        #create needed new ones        outputNodes = functionNode.get_child("output").get_child("scores").get_leaves() # get the remaining fresh        outputNodeNames =[node.get_name() for node in outputNodes]        for name in thresholdVarNames:            if name not in outputNodeNames:                logger.info(f"create new threshold score {name}")                newScore = functionNode.get_child("output").get_child("scores").create_child(name,properties={"type":"timeseries","subType":"score","creator":functionNode.get_id()})                columnsNode.add_references(newScore)                mustTriggerObserver = True    finally:        model.enable_observers()    #    #   threshold scoring starts here    #    #remove the inputNodes from the list which have no threshold to score on    inputNodes=[node for node in inputNodes if node.get_id() in thresholds]    total=None    for counter,node in enumerate(inputNodes):        progressNode.set_value(counter/len(inputNodes))        m.disable_observers()        try:            id = node.get_id()            logger.debug(f" threshold scoring on {node.get_browse_path()} ")#with {thresholds[id]['min']}, {thresholds[id]['max']}")            get = node.get_time_series()            values = get["values"]            times = get["__time"]            mask = mask_from_regions(regionFilter,times)            #now find where the limits are over/under            variableTotal = numpy.full(len(values), True,dtype=numpy.bool)            haveAnyGlobal = False            #we start with the global valid thresholds            for entry in thresholds[id]:                if entry["tags"] != []:                    continue # we don't handle thresholds now with are linked to certain annotations                haveAnyGlobal = True                outOfLimit = out_of_limits(values,entry['min'],entry['max'])#numpy.logical_or( values < entry['min'], values > entry['max'] )                outOfLimit = numpy.logical_and(outOfLimit,mask) #this is the global time filter (regions etc)                variableTotal = numpy.logical_and(outOfLimit,variableTotal)            if not haveAnyGlobal:                variableTotal = numpy.full(len(values), False, dtype=numpy.bool)            globalOutOfLimit = variableTotal #holds true for outlier and false for ok for the global valid thresholds            #now the ones bound to a annotation tag            variableTotal =  numpy.full(len(values), False,dtype=numpy.bool)            specificResults = numpy.full(len(values), False,dtype=numpy.bool) # holds the areas where the results must be replaced            haveAnyLocal = False            for entry in thresholds[id]:                if entry["tags"] == []:                    continue # those have been handled above                haveAnyLocal = True                outOfLimit = out_of_limits(values,entry['min'],entry['max'])#tooSmall | tooBig #numpy.logical_or( values < entry['min'], values > entry['max'] )                outOfLimit = numpy.logical_and(outOfLimit,mask) #this is the global time filter (regions etc)                #additionally the specific filters:                myAnnos = mh.filter_annotations(annos1,entry["tags"])                localFilter = mh.annotations_to_class_vector(myAnnos,times)                localFilter = numpy.isfinite(localFilter)                outOfLimit = numpy.logical_and(outOfLimit, localFilter)                #now we have results in outOfLimit which are valid during localFilter                # if we have already results during local Filter then this is another thresholds of the same tags                # we had already earlier, so we will "and" the outoflimit to the total, otherwise "or" it                additionalLocalResultFilter = localFilter & specificResults # true where we have results that must be "and"ed                if (numpy.any(additionalLocalResultFilter)):                    #we have results in an area that has been scored before                    newScore = variableTotal & additionalLocalResultFilter & outOfLimit                    variableTotal[additionalLocalResultFilter]=False                    variableTotal = variableTotal | newScore                else:                    #just invalidade                    variableTotal = numpy.logical_or(outOfLimit, variableTotal)  #                specificResults = numpy.logical_or(specificResults,localFilter) # remember known areas                #variableTotal = numpy.logical_and(outOfLimit,variableTotal) #            if not haveAnyLocal:                variableTotal = numpy.full(len(values), False, dtype=numpy.bool)            #now merge both            globalOutOfLimit[specificResults]=False # invalidate global results where we have specific results            variableTotal = numpy.logical_or(variableTotal,globalOutOfLimit)            outOfLimitIndices = numpy.where(variableTotal==True)            outPutNode = functionNode.get_child("output").get_child("scores").get_child(node.get_name()+"_score")            #now take the old values and set the new ones            score = numpy.full(len(values),numpy.nan,dtype=numpy.float64) # rest all            #score[mask]=numpy.nan            score[outOfLimitIndices] = values[outOfLimitIndices]            outPutNode.set_time_series(score,times)            # build the total score:            # merge in the new times, resample the total score, resampel the local score, then merge them            # the merge function will use the new values whereever there is one (empty fields are named "nan"            #  for the total score, we need a resampling to avoid the mixing of results e.g.            # two sensor have different result during a given interval, but different times, if we just merge            # we get a True, False, True,False mixture            # so we build the merge vector, first resample then merge            if type(total) is type(None):                total = TimeSeries(values = score, times = times)            else:                local = TimeSeries(values = score, times = times)                total.merge(local)            mustTriggerObserver = True        finally:            m.enable_observers()    #finally, set all values of the total score to -1 or nan    if total:        totalValues = total.get_values()        totalValues[numpy.isfinite(totalValues)]=-1        totalOutputNode.set_time_series(values=totalValues,times = total.get_times())    progressNode.set_value(1)    if mustTriggerObserver:        m.notify_observers(functionNode.get_child("output").get_child("scores").get_id(),"children")        m.notify_observers([node.get_id() for node in functionNode.get_child("output").get_child("scores").get_leaves()],"value")    return Truedef threshold_scorer(functionNode):    """        # the threshold scorer can be used in standard or streaming,        # if used in streaming (streaming = True), we only set the missing values in the output        # (the points which are numpy.inf)        # it can evaluate just one input or multiple        # for multiple: it takes the order of the inputs the same as the outputs        # the output is inf for no problem and a value for problem        # currently, streamingMode is not supported    """    logger = functionNode.get_logger()    logger.info(f">>>> in threshold_scorer {functionNode.get_browse_path()}")    streamingMode = functionNode.get_child("streaming").get_value()    #now get the input and outputs, check if number is the same    inputNodesList = functionNode.get_child("input").get_leaves()    outputNodesList =  functionNode.get_child("output").get_leaves()    if len(inputNodesList) != len(outputNodesList):        logger.error(f"input len {len(inputNodesList)} does not match output len {len(outputNodesList)}")        return False    inputNodes = {node.get_id():node for node in inputNodesList} # {nodeid:nodeObject}    outputNodes ={node.get_id():node for node in outputNodesList}  # {nodeid:nodeObject}    inoutNodes = {input.get_id():output for input,output in zip(inputNodesList,outputNodesList)}    tableLen = len(inputNodes[list(inputNodes.keys())[0]].get_value())    # get annotations remove all which we don't need    # prepare a dict of {annotationId: {"annotation":annoobject,"input":inputobjece","output"    annotationsList =  functionNode.get_child("annotations").get_leaves()    #annotations = {node.get_id():node for node in annotationsList}    thresholds = {}    for anno in functionNode.get_child("annotations").get_leaves():        if anno.get_child('tags').get_value()[0] == "threshold":            targetNodeId = anno.get_child("variable").get_leaves()[0].get_id()            if targetNodeId in inputNodes:                #this annotation is a threshold and points to one of our inputs, we take it                thresholds[anno.get_id()] = {"annotation":anno,"input":inputNodes[targetNodeId],"output":inoutNodes[targetNodeId]}    if not thresholds:        logger.error(f"we have no annotations for the thresholds of our variables")        return False    #now we have in thresholds what we have to process    for thresholdId,info in thresholds.items():        values = info["input"].get_value()        min = info["annotation"].get_child("min").get_value()        max = info["annotation"].get_child("max").get_value()        score = numpy.full(tableLen,numpy.inf)        if type(min) is type(None):            min = -numpy.inf        if type(max) is type(None):            max = numpy.inf        #set an numpy.inf where the score is ok and the value of the data where the score is not ok        score = numpy.where(numpy.logical_and(values > min,values<max), numpy.inf, values)        info["output"].set_value(score)    return Truedef threshold_drill_down(functionNode):    """        used to find the causing variable or other factors for a global error, we rely on several settings in the widget    """    logger = functionNode.get_logger()    logger.info(f">>>> in threshold_drill_down {functionNode.get_browse_path()}")    widget = functionNode.get_child("widget").get_target()    if not widget:        return False    scoreVariables = widget.get_child("scoreVariables").get_leaves()    variables = widget.get_child("selectableVariables").get_leaves()    selectedError = widget.get_child("backgroundHighlight").get_value()    drillVarOut = functionNode.get_child("drillVariables")    if selectedError == {}:        drillVarOut.add_references([], deleteAll=True)        logger.error("no background highlight selected")        return False    #now find the table time index of the selected error    tableNode = variables[0].get_table_node()    timeNode = tableNode.get_table_time_node()    logger.debug(f" scoreVariables {[v.get_browse_path() for v in scoreVariables]}")    logger.debug(f" variables {[v.get_browse_path() for v in variables]}")    logger.debug(f" selectedError {selectedError}")    #reset the output referencer    model = functionNode.get_model()    model.lock_model()    model.disable_observers()    drillVarOut.add_references([], deleteAll=True)    try:        for s in scoreVariables:            if any(numpy.isfinite(s.get_time_series(start=selectedError["left"],end=selectedError["right"])["values"])):                logger.debug(f"score has error:{s.get_name()}")                #find the variable                for v in variables:                    if v.get_name()+"_score" == s.get_name():                        logger.debug(f"variable has error in area :{v.get_name()}, add it to the drill refs")                        drillVarOut.add_references([v])    except:        model.log_error()    model.enable_observers()    model.release_model()    model.notify_observers(drillVarOut.get_id(), "forwardRefs")    return True